{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data into pandas dataframes\n",
    "\n",
    "survey_df = pd.read_csv('DEMO_D.csv')\n",
    "blood_df = pd.read_csv('BPX_D.csv')\n",
    "chol_df = pd.read_csv('TCHOL_D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10348, 11), (9950, 6), (8086, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.shape, blood_df.shape, chol_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes as per instructions\n",
    "merged_df = survey_df.merge(blood_df, on='SEQN', how='inner').merge(chol_df, on='SEQN', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values in RIDAGEYR column\n",
    "merged_df.index[merged_df['RIDAGEYR'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing AGE_AT_SCREENING and AGE_AT_EXAM columns\n",
    "merged_df['AGE_AT_SCREENING'] = merged_df['RIDAGEMN']\n",
    "merged_df['AGE_AT_EXAM'] = merged_df['RIDAGEEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   2,   18,  137,  172,  194,  252,  341,  384,  399,  427,\n",
       "            ...\n",
       "            7680, 7720, 7758, 7783, 7801, 7948, 7973, 8031, 8038, 8074],\n",
       "           dtype='int64', length=148)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null indices for AGE_AT_SCREEING\n",
    "merged_df.index[merged_df['AGE_AT_SCREENING'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,   18,  137,  172,  194,  252,  341,  384,  399,  427,  721,\n",
       "        744,  823,  927, 1016, 1021, 1028, 1137, 1190, 1240, 1267, 1338,\n",
       "       1608, 1663, 1682, 1701, 1714, 1950, 1959, 1976, 2156, 2211, 2241,\n",
       "       2252, 2255, 2331, 2518, 2534, 2599, 2653, 2777, 2837, 2843, 2897,\n",
       "       2937, 2953, 3098, 3111, 3122, 3137, 3146, 3247, 3289, 3385, 3406,\n",
       "       3415, 3427, 3457, 3473, 3477, 3498, 3513, 3530, 3548, 3655, 3700,\n",
       "       3724, 3942, 3958, 3959, 4004, 4018, 4057, 4070, 4124, 4177, 4238,\n",
       "       4274, 4291, 4332, 4339, 4369, 4371, 4413, 4450, 4519, 4531, 4543,\n",
       "       4611, 4720, 4791, 4867, 4903, 4971, 4995, 5072, 5292, 5308, 5369,\n",
       "       5403, 5489, 5548, 5569, 5588, 5629, 5720, 5752, 5868, 5870, 5940,\n",
       "       5992, 5996, 6039, 6109, 6305, 6330, 6346, 6379, 6411, 6530, 6609,\n",
       "       6628, 6796, 6848, 6853, 6868, 7034, 7061, 7116, 7243, 7345, 7391,\n",
       "       7517, 7524, 7557, 7610, 7624, 7650, 7680, 7720, 7758, 7783, 7801,\n",
       "       7948, 7973, 8031, 8038, 8074])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(merged_df.shape[0])[(merged_df['RIDAGEMN'] - (merged_df['RIDAGEYR'] * 12)).isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.28023744744002\n"
     ]
    }
   ],
   "source": [
    "# From the available data, calculating the avg difference between the (age in yr * 12) and the (age in months) \n",
    "# to make estimates for new columns\n",
    "\n",
    "avg_diff = (merged_df['RIDAGEMN'] - (merged_df['RIDAGEYR'] * 12)).sum()/merged_df.shape[0]\n",
    "print (avg_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the null values in AGE_AT_SCREENING using (age in yrs * 12) + avg_diff\n",
    "\n",
    "null_indices = merged_df['AGE_AT_SCREENING'].isnull()\n",
    "merged_df['AGE_AT_SCREENING'][null_indices] = (merged_df['RIDAGEYR'][null_indices] * 12) + int(avg_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on observations, updating the missing AGE_AT_EXAM values as AGE_AT_SCREENING + 1\n",
    "\n",
    "null_indices = merged_df['RIDAGEEX'].isnull()\n",
    "merged_df['AGE_AT_EXAM'][null_indices] = merged_df['AGE_AT_SCREENING'][null_indices] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       1026.0\n",
       "18      1026.0\n",
       "137     1026.0\n",
       "172     1026.0\n",
       "194     1026.0\n",
       "         ...  \n",
       "7948    1026.0\n",
       "7973    1026.0\n",
       "8031    1026.0\n",
       "8038    1026.0\n",
       "8074    1026.0\n",
       "Name: AGE_AT_EXAM, Length: 169, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since all null values in RIDAGEMN are for people of age greater than 85 years of age, all the missing values\n",
    "# come out to be (85*12) + 5 = 1026\n",
    "\n",
    "merged_df['AGE_AT_EXAM'][null_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating mapping from old categories to new categories\n",
    "# New categories:\n",
    "#           0: ELEMENTARY\n",
    "#           1: HIGHSCHOOL\n",
    "#           2: COLLEGE\n",
    "\n",
    "education_level_map_6_19 = {**{x:0 for x in range(13)}, 13: 1, 14: 1, 15: 1, 55: 0, 66: 0, 77: 0, 99: 0}\n",
    "education_level_map_20 = {1: 0, 2: 0, 3: 1, 4: 2, 5: 2, 7: 0, 9: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.0\n",
       "1       10.0\n",
       "2        NaN\n",
       "3        NaN\n",
       "4        NaN\n",
       "        ... \n",
       "8081    15.0\n",
       "8082     5.0\n",
       "8083     NaN\n",
       "8084     NaN\n",
       "8085    11.0\n",
       "Name: DMDEDUC3, Length: 8086, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing column for inspection\n",
    "merged_df['DMDEDUC3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the old categories to new categories into a single column\n",
    "\n",
    "merged_df['HIGHEST_EDUCATION'] =\\\n",
    "            pd.concat([merged_df['DMDEDUC3'].apply(lambda x: education_level_map_6_19[x] if x in education_level_map_6_19 else None),\n",
    "                        merged_df['DMDEDUC2'].apply(lambda x: education_level_map_20[x] if x in education_level_map_20 else None)], axis=1).max(axis=1)\n",
    "\n",
    "# setting the default class for missing values to ELEMENTARY\n",
    "merged_df['HIGHEST_EDUCATION'] = merged_df['HIGHEST_EDUCATION'].fillna(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if any missing values are remaining\n",
    "np.arange(merged_df.shape[0])[merged_df['HIGHEST_EDUCATION'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10348, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the retirement data\n",
    "retire_df = pd.read_csv('DEMO_RETIRED.CSV')\n",
    "retire_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging with existing dataframe\n",
    "merged_df = merged_df.merge(retire_df, on='SEQN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting histogram to find separation threshold for retirement\n",
    "\n",
    "pd.concat([merged_df['AGE_AT_SCREENING'][merged_df['RETIRED']==1], merged_df['AGE_AT_SCREENING'][merged_df['RETIRED']==0]], axis=1).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x7fd0a6ce0fd0>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a6ce12d0>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a6ce07d0>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a6ab5310>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a6ab58d0>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63992d0>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a6399210>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63997d0>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63a3610>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a6399190>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a6399110>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63a3910>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63af410>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63af610>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63b7250>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63b7450>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63b7090>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63b7a50>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63a3dd0>,\n",
       " <matplotlib.axis.XTick at 0x7fd0a63c1190>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a graph where the overlaps are solved\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "heights, bins = np.histogram(merged_df['AGE_AT_SCREENING'], bins=range(0, 1000, 50))\n",
    "retired_h, retired_bins = np.histogram(merged_df['AGE_AT_SCREENING'][merged_df['RETIRED']==1], bins=bins)\n",
    "not_retired_h, not_retired_bins = np.histogram(merged_df['AGE_AT_SCREENING'][merged_df['RETIRED']==0], bins=bins)\n",
    "\n",
    "width = (bins[1] - bins[0])/3\n",
    "\n",
    "ax.bar(retired_bins[:-1], retired_h, width=width, facecolor='cornflowerblue')\n",
    "ax.bar(not_retired_bins[:-1]+width, not_retired_h, width=width, facecolor='seagreen')\n",
    "ax.set_xticks(range(0, 1000, 50))\n",
    "#seaborn.despine(ax=ax, offset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on inpection 775 months looks like a sensible guess for retirement flag\n",
    "# But on checking for missing retirement values in merged data, no filling of missing values is required\n",
    "np.arange(merged_df.shape[0])[merged_df['RETIRED'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the prepared data\n",
    "merged_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Model Builing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EADDC</th>\n",
       "      <th>EAFXA</th>\n",
       "      <th>FDDBC</th>\n",
       "      <th>AFDDA</th>\n",
       "      <th>AXCXA</th>\n",
       "      <th>EXCCE</th>\n",
       "      <th>FBXFC</th>\n",
       "      <th>DFFEC</th>\n",
       "      <th>CEXAE</th>\n",
       "      <th>BBADX</th>\n",
       "      <th>CLAIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.193513</td>\n",
       "      <td>0.021062</td>\n",
       "      <td>-0.870351</td>\n",
       "      <td>4.314903</td>\n",
       "      <td>-4.260162</td>\n",
       "      <td>-1.259531</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>-0.942903</td>\n",
       "      <td>2.333260</td>\n",
       "      <td>4.678712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.667844</td>\n",
       "      <td>-3.195978</td>\n",
       "      <td>2.718651</td>\n",
       "      <td>-0.885312</td>\n",
       "      <td>2.964261</td>\n",
       "      <td>2.161336</td>\n",
       "      <td>2.008505</td>\n",
       "      <td>-0.296360</td>\n",
       "      <td>-0.610780</td>\n",
       "      <td>-2.545978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.280602</td>\n",
       "      <td>0.048539</td>\n",
       "      <td>-2.179863</td>\n",
       "      <td>-0.380866</td>\n",
       "      <td>-1.212960</td>\n",
       "      <td>2.097278</td>\n",
       "      <td>5.131315</td>\n",
       "      <td>-1.250050</td>\n",
       "      <td>2.362880</td>\n",
       "      <td>2.207307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.592376</td>\n",
       "      <td>-1.590548</td>\n",
       "      <td>2.329976</td>\n",
       "      <td>-1.416489</td>\n",
       "      <td>1.743390</td>\n",
       "      <td>3.040990</td>\n",
       "      <td>2.371740</td>\n",
       "      <td>-0.190549</td>\n",
       "      <td>0.890761</td>\n",
       "      <td>-2.671923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.236896</td>\n",
       "      <td>-0.656180</td>\n",
       "      <td>-0.381064</td>\n",
       "      <td>-2.332379</td>\n",
       "      <td>0.660684</td>\n",
       "      <td>2.055621</td>\n",
       "      <td>0.478162</td>\n",
       "      <td>-0.269513</td>\n",
       "      <td>2.614886</td>\n",
       "      <td>-3.655301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EADDC     EAFXA     FDDBC     AFDDA     AXCXA     EXCCE     FBXFC  \\\n",
       "0 -0.193513  0.021062 -0.870351  4.314903 -4.260162 -1.259531  0.175603   \n",
       "1  2.667844 -3.195978  2.718651 -0.885312  2.964261  2.161336  2.008505   \n",
       "2  2.280602  0.048539 -2.179863 -0.380866 -1.212960  2.097278  5.131315   \n",
       "3  0.592376 -1.590548  2.329976 -1.416489  1.743390  3.040990  2.371740   \n",
       "4  1.236896 -0.656180 -0.381064 -2.332379  0.660684  2.055621  0.478162   \n",
       "\n",
       "      DFFEC     CEXAE     BBADX  CLAIM  \n",
       "0 -0.942903  2.333260  4.678712      0  \n",
       "1 -0.296360 -0.610780 -2.545978      1  \n",
       "2 -1.250050  2.362880  2.207307      0  \n",
       "3 -0.190549  0.890761 -2.671923      0  \n",
       "4 -0.269513  2.614886 -3.655301      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "\n",
    "claim_df = pd.read_csv('claim_prediction.csv')\n",
    "claim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at class distribution just in case of imbalance\n",
    "\n",
    "claim_df['CLAIM'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(claim_df[['EADDC', 'EAFXA', 'FDDBC', 'AFDDA', 'AXCXA', 'EXCCE', 'FBXFC', 'DFFEC', 'CEXAE', 'BBADX']],\n",
    "                                                    claim_df['CLAIM'], \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/text_processing/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.887\n",
      "Confusion Matrix\n",
      " [[864 112]\n",
      " [114 910]]\n"
     ]
    }
   ],
   "source": [
    "# Training a One vs Rest SVM Classifier and printing metrics (accuracy and confusion matrix)\n",
    "clf = OneVsRestClassifier(SVC()).fit(X_train, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print (\"Confusion Matrix\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.56003527\n",
      "Validation score: 0.838750\n",
      "Iteration 2, loss = 0.43676217\n",
      "Validation score: 0.860000\n",
      "Iteration 3, loss = 0.41205256\n",
      "Validation score: 0.875000\n",
      "Iteration 4, loss = 0.39997446\n",
      "Validation score: 0.875000\n",
      "Iteration 5, loss = 0.39270083\n",
      "Validation score: 0.885000\n",
      "Iteration 6, loss = 0.38717948\n",
      "Validation score: 0.888750\n",
      "Iteration 7, loss = 0.38298167\n",
      "Validation score: 0.888750\n",
      "Iteration 8, loss = 0.37994596\n",
      "Validation score: 0.886250\n",
      "Iteration 9, loss = 0.37739779\n",
      "Validation score: 0.891250\n",
      "Iteration 10, loss = 0.37515007\n",
      "Validation score: 0.891250\n",
      "Iteration 11, loss = 0.37289333\n",
      "Validation score: 0.892500\n",
      "Iteration 12, loss = 0.37123505\n",
      "Validation score: 0.890000\n",
      "Iteration 13, loss = 0.36999458\n",
      "Validation score: 0.891250\n",
      "Iteration 14, loss = 0.36722214\n",
      "Validation score: 0.891250\n",
      "Iteration 15, loss = 0.36607661\n",
      "Validation score: 0.892500\n",
      "Iteration 16, loss = 0.36546207\n",
      "Validation score: 0.888750\n",
      "Iteration 17, loss = 0.36253209\n",
      "Validation score: 0.892500\n",
      "Iteration 18, loss = 0.36133338\n",
      "Validation score: 0.892500\n",
      "Iteration 19, loss = 0.36036957\n",
      "Validation score: 0.891250\n",
      "Iteration 20, loss = 0.35841753\n",
      "Validation score: 0.891250\n",
      "Iteration 21, loss = 0.35683715\n",
      "Validation score: 0.893750\n",
      "Iteration 22, loss = 0.35577884\n",
      "Validation score: 0.893750\n",
      "Iteration 23, loss = 0.35466940\n",
      "Validation score: 0.893750\n",
      "Iteration 24, loss = 0.35440522\n",
      "Validation score: 0.893750\n",
      "Iteration 25, loss = 0.35268792\n",
      "Validation score: 0.893750\n",
      "Iteration 26, loss = 0.35185842\n",
      "Validation score: 0.892500\n",
      "Iteration 27, loss = 0.35142029\n",
      "Validation score: 0.893750\n",
      "Iteration 28, loss = 0.34957765\n",
      "Validation score: 0.895000\n",
      "Iteration 29, loss = 0.34858829\n",
      "Validation score: 0.893750\n",
      "Iteration 30, loss = 0.34844371\n",
      "Validation score: 0.890000\n",
      "Iteration 31, loss = 0.34825017\n",
      "Validation score: 0.892500\n",
      "Iteration 32, loss = 0.34651193\n",
      "Validation score: 0.895000\n",
      "Iteration 33, loss = 0.34574725\n",
      "Validation score: 0.893750\n",
      "Iteration 34, loss = 0.34549434\n",
      "Validation score: 0.895000\n",
      "Iteration 35, loss = 0.34413270\n",
      "Validation score: 0.895000\n",
      "Iteration 36, loss = 0.34354842\n",
      "Validation score: 0.891250\n",
      "Iteration 37, loss = 0.34323408\n",
      "Validation score: 0.891250\n",
      "Iteration 38, loss = 0.34343245\n",
      "Validation score: 0.896250\n",
      "Iteration 39, loss = 0.34250919\n",
      "Validation score: 0.895000\n",
      "Iteration 40, loss = 0.34173275\n",
      "Validation score: 0.896250\n",
      "Iteration 41, loss = 0.33985679\n",
      "Validation score: 0.892500\n",
      "Iteration 42, loss = 0.33982973\n",
      "Validation score: 0.892500\n",
      "Iteration 43, loss = 0.33911614\n",
      "Validation score: 0.895000\n",
      "Iteration 44, loss = 0.33885462\n",
      "Validation score: 0.893750\n",
      "Iteration 45, loss = 0.33740988\n",
      "Validation score: 0.893750\n",
      "Iteration 46, loss = 0.33770017\n",
      "Validation score: 0.892500\n",
      "Iteration 47, loss = 0.33753219\n",
      "Validation score: 0.895000\n",
      "Iteration 48, loss = 0.33627513\n",
      "Validation score: 0.892500\n",
      "Iteration 49, loss = 0.33655285\n",
      "Validation score: 0.896250\n",
      "Iteration 50, loss = 0.33497543\n",
      "Validation score: 0.895000\n",
      "Iteration 51, loss = 0.33467376\n",
      "Validation score: 0.895000\n",
      "Iteration 52, loss = 0.33430818\n",
      "Validation score: 0.892500\n",
      "Iteration 53, loss = 0.33403584\n",
      "Validation score: 0.892500\n",
      "Iteration 54, loss = 0.33347169\n",
      "Validation score: 0.895000\n",
      "Iteration 55, loss = 0.33280506\n",
      "Validation score: 0.892500\n",
      "Iteration 56, loss = 0.33270517\n",
      "Validation score: 0.893750\n",
      "Iteration 57, loss = 0.33179229\n",
      "Validation score: 0.895000\n",
      "Iteration 58, loss = 0.33226145\n",
      "Validation score: 0.893750\n",
      "Iteration 59, loss = 0.33197700\n",
      "Validation score: 0.893750\n",
      "Validation score did not improve more than tol=0.000100 for 20 consecutive epochs. Stopping.\n",
      "Accuracy: 0.8855\n",
      "Confusion Matrix\n",
      " [[864 112]\n",
      " [117 907]]\n"
     ]
    }
   ],
   "source": [
    "# Training a MLP Classifier and printing metrics\n",
    "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(32, 32), learning_rate='adaptive', max_iter=1000, early_stopping=True, n_iter_no_change=20, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print (\"Confusion Matrix\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/text_processing/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.887\n",
      "Confusion Matrix\n",
      " [[864 112]\n",
      " [114 910]]\n"
     ]
    }
   ],
   "source": [
    "# Training a One vs One SVM Classifier and printing metrics\n",
    "clf1 = SVC(class_weight='balanced')\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "predicted = clf1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print (\"Confusion Matrix\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.861\n",
      "Confusion Matrix\n",
      " [[849 127]\n",
      " [151 873]]\n"
     ]
    }
   ],
   "source": [
    "# Training a Gradient Boosting Classifier and printing metrics\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print (\"Confusion Matrix\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/text_processing/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.852\n",
      "Confusion Matrix\n",
      " [[851 125]\n",
      " [171 853]]\n"
     ]
    }
   ],
   "source": [
    "# Training a Random Forest Classifier and printing metrics\n",
    "\n",
    "clf5 = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "predicted = clf5.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print (\"Confusion Matrix\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data was very clean and the classes were balanced, I did not use keras/tensorflow to build the models \n",
    "# as sklearn provides clean out of teh box implementaions for experimentation. I found in my experiments that the test \n",
    "# scores were same on one vs rest and one vs one SVM classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExercise 3: Model Evaluation\\n\\nQuestion 1\\nResponse:\\nTo determine the number of clusters in k-means clustering one of the popular methods is using the elbow curve. What this\\nmeans is that we plot the avg distance of each point from its cluster center for difference number of clusters. While plotting\\nthis curve, we notice a sudden change in slope for the decrease in distances for every increse in number of clusters. We can use\\nthis number as the number of clusters. Although, this is just a convention and the ideal number of clusters can depend on a\\nvariety of other factors.\\n\\nWe can check the quality of k-means clustering by using silhouette analysis. In this you try to compute for each data point how\\nclosely it relates to its own cluster rather than a neioghbouring cluster. A good silhouette plot means that the clusters are\\nproperly separated and have distinct properties from each other.\\n\\nQuestion 2\\nResponse:\\nLow bias and high variance might be a case of existing dependence or correlation between the input features of the data. We\\ncan deal with this by using dimensionality reduction and training the linear regression model on the transformed data. \\n\\nMoreover, we can also try to increase the regularisation factors of the regression model so that weights are more contrained\\nin order to reduce variance.\\n\\nQuestion 3\\nResponse:\\n\\n\\nQuestion4\\nResponse:\\nPart a:\\nRecall = TP/(TP + FN)\\nPrecision = TP/(TP + FP)\\nF1 score = harmonic mean of precision and recall\\n\\nrecall = 112/(112 + 6) = 0.9491\\nprecision = 112/(112 + 48) = 0.7\\nF1 score = (2 * p * r) / (p + r) = 0.8057\\n\\n\\nPart b:\\nFor the case of cancer prediction, we want to minimise the false negatives as we definitely do want to alert the people who\\nactually have camcer. For this case the metric that we will use is recall and the error we would focus on would be type 2 error.\\n\\nPart c:\\nFor this case I want to be able to find all the right recommendations but can compromise on giving certain wrong recommendations\\nas well since the user can simply ignore them. In this case, we need to again maximise True Positives and minimise missing the\\nright recommendations or minimise the false negatives. So even in this case we would use the type 2 error.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Exercise 3: Model Evaluation\n",
    "\n",
    "Question 1\n",
    "Response:\n",
    "To determine the number of clusters in k-means clustering one of the popular methods is using the elbow curve. What this\n",
    "means is that we plot the avg distance of each point from its cluster center for difference number of clusters. While plotting\n",
    "this curve, we notice a sudden change in slope for the decrease in distances for every increse in number of clusters. We can use\n",
    "this number as the number of clusters. Although, this is just a convention and the ideal number of clusters can depend on a\n",
    "variety of other factors.\n",
    "\n",
    "We can check the quality of k-means clustering by using silhouette analysis. In this you try to compute for each data point how\n",
    "closely it relates to its own cluster rather than a neioghbouring cluster. A good silhouette plot means that the clusters are\n",
    "properly separated and have distinct properties from each other.\n",
    "\n",
    "Question 2\n",
    "Response:\n",
    "Low bias and high variance might be a case of existing dependence or correlation between the input features of the data. We\n",
    "can deal with this by using dimensionality reduction and training the linear regression model on the transformed data. \n",
    "\n",
    "Moreover, we can also try to increase the regularisation factors of the regression model so that weights are more contrained\n",
    "in order to reduce variance.\n",
    "\n",
    "Question 3\n",
    "Response:\n",
    "\n",
    "\n",
    "Question4\n",
    "Response:\n",
    "Part a:\n",
    "Recall = TP/(TP + FN)\n",
    "Precision = TP/(TP + FP)\n",
    "F1 score = harmonic mean of precision and recall\n",
    "\n",
    "recall = 112/(112 + 6) = 0.9491\n",
    "precision = 112/(112 + 48) = 0.7\n",
    "F1 score = (2 * p * r) / (p + r) = 0.8057\n",
    "\n",
    "\n",
    "Part b:\n",
    "For the case of cancer prediction, we want to minimise the false negatives as we definitely do want to alert the people who\n",
    "actually have camcer. For this case the metric that we will use is recall and the error we would focus on would be type 2 error.\n",
    "\n",
    "Part c:\n",
    "For this case I want to be able to find all the right recommendations but can compromise on giving certain wrong recommendations\n",
    "as well since the user can simply ignore them. In this case, we need to again maximise True Positives and minimise missing the\n",
    "right recommendations or minimise the false negatives. So even in this case we would use the type 2 error.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CEACC</th>\n",
       "      <th>CCDEF</th>\n",
       "      <th>FAXAE</th>\n",
       "      <th>FBFFD</th>\n",
       "      <th>EDDAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>1.232260</td>\n",
       "      <td>-0.217305</td>\n",
       "      <td>3.193780</td>\n",
       "      <td>3.489992</td>\n",
       "      <td>7.792553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2.540129</td>\n",
       "      <td>0.606709</td>\n",
       "      <td>3.180950</td>\n",
       "      <td>3.464811</td>\n",
       "      <td>7.817440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>5.520271</td>\n",
       "      <td>1.470812</td>\n",
       "      <td>3.330528</td>\n",
       "      <td>2.968375</td>\n",
       "      <td>7.409152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>5.914298</td>\n",
       "      <td>2.745060</td>\n",
       "      <td>3.061706</td>\n",
       "      <td>3.440980</td>\n",
       "      <td>7.153049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE     CEACC     CCDEF     FAXAE     FBFFD     EDDAB\n",
       "0 2016-01-01  0.000000  0.000000  3.000000  3.000000  8.000000\n",
       "1 2016-02-01  1.232260 -0.217305  3.193780  3.489992  7.792553\n",
       "2 2016-03-01  2.540129  0.606709  3.180950  3.464811  7.817440\n",
       "3 2016-04-01  5.520271  1.470812  3.330528  2.968375  7.409152\n",
       "4 2016-05-01  5.914298  2.745060  3.061706  3.440980  7.153049"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data\n",
    "anomaly_df = pd.read_csv('anomaly_detection_dates.csv')\n",
    "anomaly_df['DATE'] = pd.to_datetime(anomaly_df['DATE'])\n",
    "anomaly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting a pca model on the data\n",
    "pca = PCA()\n",
    "pca.fit(anomaly_df[['CEACC', 'CCDEF', 'FAXAE', 'FBFFD', 'EDDAB']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.09395304,  4.54227171,  1.52110246,  1.31939925,  0.40122541])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at variance distribution along different components\n",
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining transformed data\n",
    "X_transformed = pca.transform(anomaly_df[['CEACC', 'CCDEF', 'FAXAE', 'FBFFD', 'EDDAB']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "                means_init=None, n_components=1, n_init=1, precisions_init=None,\n",
       "                random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "                verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a single gaussian distribution on the new components\n",
    "# The gaussian is fit on the transformed data since the gaussian dostribution is only able to measure the mean and\n",
    "# variance along the dimensions of data. So using the directions that capture variance in the data in a better way \n",
    "# will create a better fitting gaussian distribution\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture()\n",
    "\n",
    "# gmm.fit(X_transformed)\n",
    "gmm.fit(X_transformed[~anomaly_df['DATE'].isin(pd.date_range(pd.Timestamp(2016,2,14), pd.Timestamp(2016,2,21), freq='1D'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.39181753])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.score_samples(X_transformed[anomaly_df['DATE']==pd.Timestamp(2016,1,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CEACC</th>\n",
       "      <th>CCDEF</th>\n",
       "      <th>FAXAE</th>\n",
       "      <th>FBFFD</th>\n",
       "      <th>EDDAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>6.045535</td>\n",
       "      <td>2.805374</td>\n",
       "      <td>0.999693</td>\n",
       "      <td>3.159062</td>\n",
       "      <td>8.427402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE     CEACC     CCDEF     FAXAE     FBFFD     EDDAB\n",
       "29 2016-01-30  6.045535  2.805374  0.999693  3.159062  8.427402"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_df[anomaly_df['DATE']==pd.Timestamp(2016,1,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.99588804, -13.15484824,  -9.38480145, -11.42256434,\n",
       "       -12.94388762,  -9.2925613 , -11.02183352, -11.00720977])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the values for the data that the analyst has labelled anomalous\n",
    "\n",
    "gmm.score_samples(X_transformed[anomaly_df['DATE'].isin(pd.date_range(pd.Timestamp(2016,2,14), pd.Timestamp(2016,2,21), freq='1D'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.443933911521242"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average log-likelihood of the data\n",
    "gmm.score(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the probability for each sample in the data\n",
    "probs = gmm.score_samples(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1]), -10.597399251833064),\n",
       " (array([44]), -11.99588804068432),\n",
       " (array([45]), -13.154848236327032),\n",
       " (array([47]), -11.422564341015294),\n",
       " (array([48]), -12.943887616674806),\n",
       " (array([50]), -11.021833518804408),\n",
       " (array([51]), -11.007209770443788),\n",
       " (array([52]), -12.606524604681995),\n",
       " (array([53]), -11.145595303018984),\n",
       " (array([56]), -10.614614606249784),\n",
       " (array([65]), -10.512234064713715),\n",
       " (array([66]), -10.68721572821118),\n",
       " (array([117]), -11.3585314342297),\n",
       " (array([118]), -11.115956236482601),\n",
       " (array([126]), -10.570776427113113),\n",
       " (array([152]), -10.515917701094919),\n",
       " (array([270]), -10.840657303090993),\n",
       " (array([291]), -10.798029030012737),\n",
       " (array([292]), -10.809715760030548),\n",
       " (array([293]), -11.346250638703605),\n",
       " (array([296]), -10.933226404383609),\n",
       " (array([299]), -10.802127988327095),\n",
       " (array([318]), -15.925895857445319),\n",
       " (array([319]), -14.621302802171199),\n",
       " (array([320]), -15.81138376690645),\n",
       " (array([321]), -20.07364318587062),\n",
       " (array([322]), -17.195322256707406),\n",
       " (array([323]), -20.057245739397985),\n",
       " (array([324]), -21.871062983535438),\n",
       " (array([343]), -11.21776809701974),\n",
       " (array([344]), -10.591597834335378),\n",
       " (array([348]), -11.516956867400639),\n",
       " (array([350]), -13.60124183033048),\n",
       " (array([351]), -11.339536378867654),\n",
       " (array([352]), -14.28156736552639),\n",
       " (array([353]), -13.318825366304742),\n",
       " (array([354]), -16.181870547100356),\n",
       " (array([355]), -15.236528844208658),\n",
       " (array([356]), -15.243915757047164),\n",
       " (array([357]), -17.353906282989087),\n",
       " (array([358]), -17.492835398844846),\n",
       " (array([359]), -16.764116094353174),\n",
       " (array([360]), -17.23645156848611),\n",
       " (array([361]), -15.394490092573141),\n",
       " (array([362]), -15.192394050689385),\n",
       " (array([363]), -17.425356341157354),\n",
       " (array([364]), -17.857756859657453)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having a look at the days that are returned if we decide on a probility threshold of 10.5\n",
    "list(zip(np.argwhere(-probs>10.5), probs[-probs>10.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.39181753, -10.59739925,  -9.87247989,  -9.92616214,\n",
       "        -9.31401618,  -9.40372786,  -9.3285147 ,  -9.87208832,\n",
       "        -9.37383162,  -9.09176818,  -8.94006613,  -8.82520043,\n",
       "        -8.94866629,  -9.13373005,  -8.94318274,  -9.17048995,\n",
       "        -9.30787478,  -8.93821037,  -8.3453876 ,  -8.60784125,\n",
       "        -8.2574543 ,  -8.36621261,  -8.23085255,  -8.66468002,\n",
       "        -8.7438937 ,  -9.48897633,  -9.01132069,  -8.43617306,\n",
       "        -8.63069884,  -7.79115971,  -7.85908375,  -8.17741097,\n",
       "        -8.06066436,  -8.22315176,  -8.4546567 ,  -8.64430006,\n",
       "        -8.62911078,  -8.86418454,  -9.00383484,  -8.91833749,\n",
       "        -8.60497354,  -8.86396214,  -8.72447158,  -9.05944019,\n",
       "       -11.99588804, -13.15484824,  -9.38480145, -11.42256434,\n",
       "       -12.94388762,  -9.2925613 , -11.02183352, -11.00720977,\n",
       "       -12.6065246 , -11.1455953 , -10.11381741, -10.17262237,\n",
       "       -10.61461461,  -9.58257959,  -9.52707202, -10.13856278,\n",
       "        -9.59656294, -10.26655076,  -9.06963555,  -8.85160664,\n",
       "       -10.12363934, -10.51223406, -10.68721573, -10.34439189,\n",
       "        -8.89241241,  -8.917209  ,  -9.60238318,  -8.95668143,\n",
       "        -8.97698622,  -8.76165896,  -8.83332205,  -8.28435368,\n",
       "        -7.62715852,  -7.78958246,  -8.7092277 ,  -8.25977392,\n",
       "        -7.80143879,  -8.82356758,  -8.10317471,  -8.06221371,\n",
       "        -7.31785995,  -7.56944314,  -8.39234961,  -8.5736458 ,\n",
       "        -9.27044765,  -9.46755469,  -8.18304924,  -7.77371273,\n",
       "        -7.47950205,  -8.07789274,  -7.7620496 ,  -7.71944294,\n",
       "        -8.26549846,  -8.05135627,  -9.49425566,  -8.42972498,\n",
       "        -8.17993724,  -8.42178259,  -8.76065095,  -8.91904892,\n",
       "        -8.49662721,  -9.87265421,  -9.91758635,  -8.92160255,\n",
       "        -9.24692677,  -8.57080866,  -8.49275129,  -7.97071518,\n",
       "        -7.8828916 ,  -9.63858307,  -9.72522237, -10.40855183,\n",
       "       -10.24723974, -11.35853143, -11.11595624, -10.15776078,\n",
       "        -9.51877838,  -9.63717071,  -9.68921706, -10.40042373,\n",
       "        -9.50101008,  -9.71802029, -10.57077643,  -9.2395996 ,\n",
       "        -9.16337436,  -9.46173773,  -9.63924267, -10.38505635,\n",
       "       -10.48028038,  -9.72069542,  -9.94782288,  -9.18981071,\n",
       "        -8.75306209,  -8.76833059,  -8.86849489,  -9.04786577,\n",
       "       -10.15845828,  -8.80281435,  -8.20327837,  -8.49921959,\n",
       "        -9.14252803,  -9.9046943 ,  -9.55774268,  -9.93621512,\n",
       "        -9.76039503,  -9.06101584, -10.10246416, -10.38736026,\n",
       "       -10.5159177 ,  -9.1715047 ,  -8.8594926 ,  -8.91018694,\n",
       "        -8.92584892,  -9.54230566,  -9.33998611,  -9.30337899,\n",
       "        -9.46766763,  -9.79988668,  -9.39866502,  -9.3734051 ,\n",
       "        -9.4475991 ,  -8.69051235,  -8.33005805,  -7.81280668,\n",
       "        -8.12245204,  -8.06313164,  -7.65470372,  -8.29194086,\n",
       "        -7.89392113,  -7.91660499,  -7.85259599,  -7.74768877,\n",
       "        -7.53101448,  -7.63493379,  -7.65108563,  -7.45286725,\n",
       "        -7.34002699,  -7.24625971,  -7.37904963,  -7.27796171,\n",
       "        -7.73712709,  -8.85710837,  -9.69227231,  -9.28967756,\n",
       "       -10.36506391,  -9.50328907,  -8.56044823,  -8.77527927,\n",
       "        -8.29510069,  -8.44199373,  -8.28986837,  -8.16537928,\n",
       "        -7.91835716,  -8.31741674,  -8.04369988,  -7.43581335,\n",
       "        -7.72665187,  -7.58582203,  -8.25695962,  -8.749081  ,\n",
       "        -8.14336504,  -8.5823366 ,  -7.71188017,  -8.10439868,\n",
       "        -8.27841917,  -8.69533419,  -8.63659639,  -8.70075695,\n",
       "        -8.5962506 ,  -8.70392581,  -8.19541173,  -8.96500034,\n",
       "        -9.96296872,  -9.43007061,  -9.39453612,  -9.45140523,\n",
       "        -9.94132891, -10.07131295,  -9.68397646,  -9.52924473,\n",
       "        -9.00165581,  -8.92490349,  -8.88910739,  -9.79077211,\n",
       "        -9.27670616,  -8.43726105,  -8.38850712,  -8.73085884,\n",
       "        -8.25246427,  -8.38790896,  -8.21115935,  -9.05982483,\n",
       "        -8.03237229,  -8.04889903,  -8.11899177,  -7.88433528,\n",
       "        -7.87304277,  -7.74967352,  -8.16339385,  -8.6446957 ,\n",
       "        -8.59841425,  -8.93100548,  -8.96060085,  -9.12197172,\n",
       "        -9.29746523,  -9.66313246,  -9.17085364,  -9.40971379,\n",
       "        -9.15075736,  -8.76692127,  -9.24515302,  -9.91113883,\n",
       "        -9.17432827,  -9.29245318,  -8.97718243,  -8.86240457,\n",
       "        -8.7934047 ,  -8.97949352,  -8.6848102 ,  -8.4113085 ,\n",
       "        -8.66860566,  -9.23152612,  -9.3478533 ,  -9.45113518,\n",
       "        -9.95004094,  -9.91837559, -10.8406573 ,  -9.64508112,\n",
       "        -9.35309357,  -9.05093338,  -8.78429477,  -8.04900043,\n",
       "        -7.82764251,  -7.92538303,  -7.94483477,  -7.66132235,\n",
       "        -7.65035875,  -7.95515735,  -8.19509408,  -8.37582578,\n",
       "        -8.32463358,  -8.7516029 ,  -8.39921176,  -8.90789714,\n",
       "        -8.8687955 ,  -8.90980136,  -8.82690878, -10.79802903,\n",
       "       -10.80971576, -11.34625064, -10.01989502, -10.37501476,\n",
       "       -10.9332264 ,  -9.08782146,  -9.28728549, -10.80212799,\n",
       "        -8.81012464,  -8.53014584,  -8.7645041 ,  -8.16616338,\n",
       "        -9.58179811,  -8.53900651,  -8.44775746,  -9.12189438,\n",
       "        -8.61473491,  -8.54798731,  -8.25201718,  -8.09464516,\n",
       "        -8.3906011 ,  -8.50604083,  -9.78354962,  -9.41291599,\n",
       "        -8.02647359,  -7.19104704, -15.92589586, -14.6213028 ,\n",
       "       -15.81138377, -20.07364319, -17.19532226, -20.05724574,\n",
       "       -21.87106298,  -8.93819095,  -7.96149638,  -8.54338942,\n",
       "        -8.24677014,  -8.01780886,  -8.09995631,  -8.2233758 ,\n",
       "        -8.54990677,  -8.5935609 ,  -8.25729286,  -8.46104835,\n",
       "        -9.15094373,  -8.78356028,  -8.50177805,  -8.19738195,\n",
       "        -8.9624537 ,  -9.14592333,  -9.6566392 , -11.2177681 ,\n",
       "       -10.59159783,  -9.8757551 , -10.39018388,  -9.98871833,\n",
       "       -11.51695687,  -9.26149968, -13.60124183, -11.33953638,\n",
       "       -14.28156737, -13.31882537, -16.18187055, -15.23652884,\n",
       "       -15.24391576, -17.35390628, -17.4928354 , -16.76411609,\n",
       "       -17.23645157, -15.39449009, -15.19239405, -17.42535634,\n",
       "       -17.85775686])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CEACC</th>\n",
       "      <th>CCDEF</th>\n",
       "      <th>FAXAE</th>\n",
       "      <th>FBFFD</th>\n",
       "      <th>EDDAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>4.043725</td>\n",
       "      <td>-1.219565</td>\n",
       "      <td>0.905195</td>\n",
       "      <td>2.288989</td>\n",
       "      <td>7.709211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>4.576282</td>\n",
       "      <td>-1.492071</td>\n",
       "      <td>0.899782</td>\n",
       "      <td>2.130575</td>\n",
       "      <td>7.968487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>2.210294</td>\n",
       "      <td>-0.576621</td>\n",
       "      <td>-0.044090</td>\n",
       "      <td>3.037759</td>\n",
       "      <td>7.975463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016-02-17</td>\n",
       "      <td>2.482837</td>\n",
       "      <td>-1.658767</td>\n",
       "      <td>-0.550546</td>\n",
       "      <td>4.215023</td>\n",
       "      <td>7.828515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>4.480263</td>\n",
       "      <td>-1.545013</td>\n",
       "      <td>-0.934196</td>\n",
       "      <td>2.485914</td>\n",
       "      <td>8.099992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2016-02-19</td>\n",
       "      <td>1.943677</td>\n",
       "      <td>-0.539503</td>\n",
       "      <td>-1.623672</td>\n",
       "      <td>3.877839</td>\n",
       "      <td>8.551997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>2.586666</td>\n",
       "      <td>-1.487198</td>\n",
       "      <td>-2.121800</td>\n",
       "      <td>3.344881</td>\n",
       "      <td>8.535509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>2.934930</td>\n",
       "      <td>1.413589</td>\n",
       "      <td>-2.289341</td>\n",
       "      <td>2.777793</td>\n",
       "      <td>8.198616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE     CEACC     CCDEF     FAXAE     FBFFD     EDDAB\n",
       "44 2016-02-14  4.043725 -1.219565  0.905195  2.288989  7.709211\n",
       "45 2016-02-15  4.576282 -1.492071  0.899782  2.130575  7.968487\n",
       "46 2016-02-16  2.210294 -0.576621 -0.044090  3.037759  7.975463\n",
       "47 2016-02-17  2.482837 -1.658767 -0.550546  4.215023  7.828515\n",
       "48 2016-02-18  4.480263 -1.545013 -0.934196  2.485914  8.099992\n",
       "49 2016-02-19  1.943677 -0.539503 -1.623672  3.877839  8.551997\n",
       "50 2016-02-20  2.586666 -1.487198 -2.121800  3.344881  8.535509\n",
       "51 2016-02-21  2.934930  1.413589 -2.289341  2.777793  8.198616"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_df[anomaly_df['DATE'].isin(pd.date_range(pd.Timestamp(2016,2,14), pd.Timestamp(2016,2,21), freq='1D'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to detect anomalous readings based on the description in the problem\n",
    "\n",
    "def detect_anomaly(anomaly_df):\n",
    "    pca = PCA()\n",
    "    pca.fit(anomaly_df[['CEACC', 'CCDEF', 'FAXAE', 'FBFFD', 'EDDAB']])\n",
    "    X_transformed = pca.transform(anomaly_df[['CEACC', 'CCDEF', 'FAXAE', 'FBFFD', 'EDDAB']])\n",
    "    gmm = GaussianMixture()\n",
    "    gmm.fit(X_transformed)\n",
    "    probs = gmm.score_samples(X_transformed)\n",
    "    indices = np.where(-probs > 10.5)[0]\n",
    "    tolerance = 2\n",
    "    anomalous_ind = []\n",
    "    start_i = -2\n",
    "    prev_i = -tolerance - 1\n",
    "    # print (probs)\n",
    "    # print (indices)\n",
    "    for i in indices:\n",
    "        if i - prev_i <= 1 and start_i < 0:\n",
    "            start_i = prev_i\n",
    "        elif start_i >= 0 and i - prev_i > tolerance:\n",
    "            if prev_i - start_i < 14:\n",
    "                anomalous_ind.append(list(range(start_i, prev_i + 1)))\n",
    "            start_i = -2\n",
    "        prev_i = i\n",
    "    if start_i >= 0:\n",
    "        if prev_i - start_i < 14:\n",
    "            anomalous_ind.extend(list(range(start_i, indices[-1] + 1)))\n",
    "        # print (prev_i, start_i)\n",
    "    dates = [list(anomaly_df['DATE'][ind]) for ind in anomalous_ind]\n",
    "    # print (dates)\n",
    "    return dates\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Timestamp('2016-02-14 00:00:00'),\n",
       "  Timestamp('2016-02-15 00:00:00'),\n",
       "  Timestamp('2016-02-16 00:00:00'),\n",
       "  Timestamp('2016-02-17 00:00:00'),\n",
       "  Timestamp('2016-02-18 00:00:00'),\n",
       "  Timestamp('2016-02-19 00:00:00'),\n",
       "  Timestamp('2016-02-20 00:00:00'),\n",
       "  Timestamp('2016-02-21 00:00:00'),\n",
       "  Timestamp('2016-02-22 00:00:00'),\n",
       "  Timestamp('2016-02-23 00:00:00')],\n",
       " [Timestamp('2016-04-27 00:00:00'), Timestamp('2016-04-28 00:00:00')],\n",
       " [Timestamp('2016-10-18 00:00:00'),\n",
       "  Timestamp('2016-10-19 00:00:00'),\n",
       "  Timestamp('2016-10-20 00:00:00')],\n",
       " [Timestamp('2016-11-14 00:00:00'),\n",
       "  Timestamp('2016-11-15 00:00:00'),\n",
       "  Timestamp('2016-11-16 00:00:00'),\n",
       "  Timestamp('2016-11-17 00:00:00'),\n",
       "  Timestamp('2016-11-18 00:00:00'),\n",
       "  Timestamp('2016-11-19 00:00:00'),\n",
       "  Timestamp('2016-11-20 00:00:00')],\n",
       " [Timestamp('2016-09-12 00:00:00'), Timestamp('2016-10-12 00:00:00')]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the dates with detected anomalies\n",
    " \n",
    "detect_anomaly(anomaly_df)\n",
    "\n",
    "# we observe based on these results we observe 3 anomalous periods between 10/01/2016 to 12/30/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ee36563a591ec48388a30193b4a20641a660eb311b00f0fbacaf8e23d5da924"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('text_processing': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}